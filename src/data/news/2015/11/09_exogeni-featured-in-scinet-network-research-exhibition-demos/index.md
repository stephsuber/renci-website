---
title: "ExoGENI featured in SCinet Network Research Exhibition demos"
slug: exogeni-featured-in-scinet-network-research-exhibition-demos
spotlight: false
publish_date: 2015-11-09
author: 
featuredImage: null
groups:
    - nrig
projects:
    - exogeni
people:
    - 
teams: 
    - 
collaborations:
    - 
tags:
    - ["networking","testbed"]
---
<a href="http://renci.org/wp-content/uploads/2015/11/ExoGENI-logo2.png"><img class="alignright size-thumbnail wp-image-15171" src="http://renci.org/wp-content/uploads/2015/11/ExoGENI-logo2-150x150.png" alt="ExoGENI logo2" width="150" height="150" /></a>AUSTIN, TEXAS - Each year the SC conference, the annual gathering of industry and research experts in high performance computing, networking, storage and analysis, sets up one of the most powerful and advanced networks in the world: SCinet.

<!--more-->

Volunteers from around the world create SCinet as a very high-capacity network that supports the revolutionary applications and experiments that are a hallmark of the SC conference. This year SCinet will link the Austin Convention Center to research and commercial networks around the world.

SCinet serves as the platform for exhibitors to demonstrate advanced computing resources and applications by supporting a wide variety of bandwidth-driven applications including supercomputing and cloud computing. The network also showcases a wide range of advanced networking experiments through the SCinet Network Research Exhibition (NRE).

This year 25 demonstrations will participate in SCinet NRE, including four that will use ExoGENI, a nationwide test bed for advanced networking and networked cloud computing. Led by RENCI with collaborators at Duke University, ExoGENI is part of the National Science Foundation’s GENI (Global Environment for Network Innovations) initiative. In effect, ExoGENI is a widely distributed networked infrastructure-as-a-service (NIaaS) platform geared towards experimentation and computational tasks.

Below is information on the SCinet NRE demonstrations that will use ExoGENI, including two that will take place in the RENCI booth. For a complete list of SC15 NRE demos click here. For more information on ExoGENI visit the ExoGENI <a href="http://www.exogeni.net/" target="_blank">website</a> or the RENCI <a href="http://renci.org/research/geni/" target="_blank">website</a>.

<strong>SCinet NRE demos featuring ExoGENI</strong>

<strong>Title:</strong> Network Security @ 100 Gbps
<strong>Booth:</strong> CIENA #933
<strong>Description</strong>: This demonstration will showcase SARNET (Security Autonomous Response with programmable NETworks), based on Network Function Virtualization and cloud techniques that enable networks to defend themselves when under (ddos) attacks. SARNET demonstrates the result of research that is exploring how to obtain the knowledge to create ICT systems that model their state and discover exceptional situations by observations and reasoning including if and how an attack is developing. Based on analysis, SARNET determines the associated risks and responds by calculating the effect of counter measures on states and risks and then selects and implements the best response. The core platform used is ExoGENI, a national scale test bed with international extensions on 100 Gbps paths - part of the National Science Foundation’s Global Environment for Network Innovations (GENI) distributed test bed, supporting empirical network science research. ExoGENI integrates the GENI environment with open cloud computing (OpenStack) and dynamic circuit fabrics. ExoGENI orchestrates a federation of cloud sites throughout the US and international sites, using R&amp;E networks and native IaaS API to integrate GENI resources.

<strong>Title: Virtualized Science DMZ as a service</strong><strong>
<strong>Booth:</strong></strong> RENCI #181
<strong>Description:</strong> Many campuses are installing ScienceDMZs to support efficient large-scale scientific data transfers. There’s a need to create custom configurations of ScienceDMZs for different groups on campus. Network function virtualization (NFV) combined with compute and storage virtualization enables a multi-tenant approach to deploying virtual ScienceDMZs. It makes it possible for campus IT or NREN organizations to quickly deploy well-tuned ScienceDMZ instances targeted at a particular collaboration or project. This demo shows a prototype implementation of ScienceDMZ-as-a-Service using ExoGENI racks (ExoGENI is part of NSF GENI federation of test beds) deployed at StarLight facility in Chicago and at NERSC. The virtual ScienceDMZs deployed on-demand in these racks connect to a data source at Argonne National Lab and a compute cluster at NERSC to provide seamless end-to-end high-speed data transfers of data acquired from Argonne’s Advanced Photon Source (APS) to be processed at NERSC. The ExoGENI racks dynamically instantiate necessary compute virtual resources for ScienceDMZ functions and connect to each other on-demand using ESnet’s OSCARS and Internet2’s AL2S system.

<strong>Title: Resource Aware Data-centric collaboration Infrastructure (RADII)</strong><strong>
<strong>Booth: </strong></strong>RENCI #181
<strong>Description:</strong> Data-centric collaborations have become the engines of scientific research. However, these collaborations can be difficult to realize because the appropriate infrastructure, including dedicated network infrastructure needed to transfer large data sets, is often unavailable and few mechanisms exist for controlling data access. Solutions that bridge the gap between infrastructure and data management technologies are needed to make data-centric collaborations feasible. This demonstration presents a novel cloud-based platform, called Resource Aware Data-centrIc collaboratIon Infrastructure (RADII), that addresses these challenges. RADII integrates the Open Resource Control Architecture (ORCA) and integrated Rule Oriented Data System (iRODS) to allow scientists to create and manage collaborations. The research team will show how scientists can use RADII to create data-centric collaborations using data-flow diagram formalisms. RADII provides a user-friendly graphical interface that scientists can use to determine their infrastructure requirements and data access policies. The policies are then automatically mapped to the infrastructure and data management system by the RADII software. The demonstration will also show how RADII allows scientists to manage their collaborations throughout the lifecycle of a project. The team has deployed RADII on ExoGENI to support collaborations over a worldwide federated environment of resources and infrastructure.

<strong>Title: </strong><strong>High Performance Science Networking @ 100Gbps </strong><strong>
</strong><strong>Booth:</strong> iCAIR #749
<strong>Description:</strong> This demonstration will showcase highly programmable networking techniques for controlling individual high capacity streams over global 100 Gbps network paths. In addition it will showcase SDN techniques for managing dynamic multi-domain global 100 Gbps WAN paths - integrated with a Network Service Interface 2.0 (NSI) based technique for direct edge path provisioning of a 100Gbps high performance optical switch and specially configured Ciena ExoGENI racks which can output more than 170Gbps worth of data, controlled by the Open Resource Control Architecture (ORCA) which allows the specification of which LAN speed each devices can use to interact at the Data Layer. ExoGENI is a national scale test bed with international extensions - part of the National Science Foundation's Global Environment for Network Innovations (GENI) distributed test bed, supporting empirical network science research. ExoGENI integrates the GENI environment with open cloud computing (OpenStack), dynamic circuit fabrics, and dynamically allocated storage and compute devices. ExoGENI orchestrates a federation of cloud sites across the world, using R&amp;E networks and native IaaS API, while exposing a variety of user-facing APIs, including GENI AM API.

&nbsp;
